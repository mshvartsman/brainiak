{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A faster way of doing TFA\n",
    "\n",
    "The basic TFA generative model is: \n",
    "\n",
    "$$\n",
    "Y \\mid W, F \\sim \\mathcal{MN}(WF, \\sigma^2 I, I), \n",
    "$$\n",
    "\n",
    "where F is the matrix containing the factors. We can put a trivial i.i.d. normal prior on $W$, giving us the following marginal: \n",
    "\n",
    "$$\n",
    "Y \\mid F \\sim \\mathcal{MN}(0, \\sigma^2 I , F^T F + I). \n",
    "$$\n",
    "We can apply the matrix determinant and inversion lemmas to replace the $F^T F$ inverse with a much nicer $FF^T$ inverse, and compute the marginal log-likelihood pretty efficiently, autodiff through it, and optimize by L-BFGS-B. \n",
    "\n",
    "In contrast to vanilla TFA, this way of doing things: \n",
    "- Gets rid of the coordinate ascent bit completely: we find $F$ marginalizing over $W$ and then compute $W$ in closed form once. \n",
    "- Gets rid of finite differences, which is slow. \n",
    "- Gets rid of a massive jacobian that needs to be subsampled (there's a tradeoff here: we're not exploiting the least squares structure any more). \n",
    "- Can be computed on GPU if we'd like. \n",
    "\n",
    "And it's still theoretically compatible with HTFA (just not implemented yet). Let's see how it goes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from brainiak.factoranalysis.tfa import TFA\n",
    "from brainiak.factoranalysis.fast_tfa import FastTFA, get_factormat\n",
    "\n",
    "def benchmark_tfa(v, t, k, noise, skip_slow=False):\n",
    "    R = np.random.randint(2, high=102, size=(v, 3)).astype(\"float64\")\n",
    "    centers = np.random.randint(2, high=102, size=(k, 3)).astype(\"float64\")\n",
    "    widths = np.abs(np.random.normal(loc=0, scale=np.std(R)**2, size=(k, 1)))\n",
    "    F = get_factormat(R, centers, widths).numpy()\n",
    "    W = np.random.normal(size=(t, k))\n",
    "    X = W @ F + np.random.normal(size=(t, v))*noise\n",
    "\n",
    "    fast_tfa = FastTFA(k=k)\n",
    "    tfa_subsamp = TFA(K=k, max_num_tr=t//10, max_num_voxel=v//20)\n",
    "    tfa_full = TFA(K=k, max_num_tr=t, max_num_voxel=v)\n",
    "\n",
    "    print(\"\\nFast TFA:\")\n",
    "    %time fast_tfa.fit(X, R)\n",
    "    fast_tfa_mse = np.mean((X - fast_tfa.W_ @ fast_tfa.F_)**2)\n",
    "    print(f\"MSE={fast_tfa_mse}\")\n",
    "\n",
    "    print(\"\\nSubsampled regular TFA:\")\n",
    "    %time tfa_subsamp.fit(X.T, R)\n",
    "    tfa_subsamp_mse = np.mean((X.T - tfa_subsamp.F_ @ tfa_subsamp.W_)**2)\n",
    "    print(f\"MSE={tfa_subsamp_mse}\")\n",
    "    if skip_slow:\n",
    "        return\n",
    "    print(\"\\nFull TFA\")\n",
    "    %time tfa_full.fit(X.T, R)\n",
    "    tfa_full_mse = np.mean((X.T - tfa_full.F_ @ tfa_full.W_)**2)\n",
    "    print(f\"MSE={tfa_full_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fast TFA:\n",
      "CPU times: user 609 ms, sys: 46.9 ms, total: 656 ms\n",
      "Wall time: 529 ms\n",
      "MSE=0.01873000207327146\n",
      "\n",
      "Subsampled regular TFA:\n",
      "CPU times: user 5.98 s, sys: 1.81 s, total: 7.8 s\n",
      "Wall time: 1.68 s\n",
      "MSE=0.06499834081823767\n",
      "\n",
      "Full TFA\n",
      "CPU times: user 38.1 s, sys: 27.3 s, total: 1min 5s\n",
      "Wall time: 9.08 s\n",
      "MSE=0.010293511521374237\n"
     ]
    }
   ],
   "source": [
    "benchmark_tfa(v=100, t=50, k=3, noise=0.1) # tiny problem with basically no noise, sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fast TFA:\n",
      "CPU times: user 312 ms, sys: 344 ms, total: 656 ms\n",
      "Wall time: 271 ms\n",
      "MSE=0.9772830747585769\n",
      "\n",
      "Subsampled regular TFA:\n",
      "CPU times: user 2.91 s, sys: 1.59 s, total: 4.5 s\n",
      "Wall time: 945 ms\n",
      "MSE=1.001510387817818\n",
      "\n",
      "Full TFA\n",
      "CPU times: user 2.27 s, sys: 1.78 s, total: 4.05 s\n",
      "Wall time: 597 ms\n",
      "MSE=1.002109741576849\n"
     ]
    }
   ],
   "source": [
    "benchmark_tfa(v=100, t=50, k=3, noise=1) # same tiny problem with a bit more noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fast TFA:\n",
      "CPU times: user 7.12 s, sys: 1.16 s, total: 8.28 s\n",
      "Wall time: 1.82 s\n",
      "MSE=0.977909290668985\n",
      "\n",
      "Subsampled regular TFA:\n",
      "CPU times: user 20.9 s, sys: 13.3 s, total: 34.2 s\n",
      "Wall time: 4.65 s\n",
      "MSE=1.0278639367093334\n"
     ]
    }
   ],
   "source": [
    "benchmark_tfa(v=500, t=200, k=15, noise=1, skip_slow=True) # still beats subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fast TFA:\n",
      "CPU times: user 32 s, sys: 1.7 s, total: 33.7 s\n",
      "Wall time: 5.35 s\n",
      "MSE=0.9931124439167173\n",
      "\n",
      "Subsampled regular TFA:\n",
      "CPU times: user 3.38 s, sys: 1.83 s, total: 5.2 s\n",
      "Wall time: 751 ms\n",
      "MSE=1.030644716273053\n"
     ]
    }
   ],
   "source": [
    "benchmark_tfa(v=1000, t=200, k=15, noise=1, skip_slow=True) # larger problem, subsampling starts really helping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fast TFA:\n",
      "CPU times: user 8min 4s, sys: 8.11 s, total: 8min 13s\n",
      "Wall time: 1min 16s\n",
      "MSE=0.9904045683317866\n",
      "\n",
      "Subsampled regular TFA:\n",
      "CPU times: user 4.59 s, sys: 1.47 s, total: 6.06 s\n",
      "Wall time: 855 ms\n",
      "MSE=1.0340202418558002\n"
     ]
    }
   ],
   "source": [
    "benchmark_tfa(v=2000, t=400, k=20, noise=1, skip_slow=True) # ok, now it gets really bad for our \"fast\" TFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "Fast TFA is more accurate at reconstruction (by not subsampling and integrating over W), is faster than full-TFA but not nearly as fast as the subsampling version of regular-TFA for more practical problems. Next step: probably SGD of some sort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brainiak] *",
   "language": "python",
   "name": "conda-env-brainiak-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
